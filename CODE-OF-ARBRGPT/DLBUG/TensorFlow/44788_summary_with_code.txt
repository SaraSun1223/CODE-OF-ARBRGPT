[Title] bad shape of index returned by UniqueWithCountsV2 in graph mode

<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"`
2. TF 2.0: `python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"`


**Describe the current behavior**
The index returned by `tf.raw_ops.UniqueWithCountsV2` does not have the right shape when used in graph mode.

**Describe the expected behavior**
The index returned by `tf.raw_ops.UniqueWithCountsV2` should have the right shape when used iin graph mode.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.


Here's some simple code to illustrate the problem:

```python
import tensorflow as tf

# The same function: decorated with tf.function (will be executed in graph mode) and 
# not decorated (will be executed in eager mode)

@tf.function
def graph_func(x):
    unique_input_ids, idx, counts = tf.raw_ops.UniqueWithCountsV2(x=x, axis=[0])
    tf.print('idx shape', tf.shape(idx), 'idx', idx)
    return x

def eager_func(x):
    unique_input_ids, idx, counts = tf.raw_ops.UniqueWithCountsV2(x=x, axis=[0])
    tf.print('idx shape', tf.shape(idx), 'idx', idx)
    return x

c = tf.constant([[0,0,1], 
                 [0,0,1], 
                 [0,0,2], 
                 [0,0,1]])
_ = graph_func(c)
_ = eager_func(c)
```
Prints this:
```
idx shape [4 3] idx [0 0 1 0]
idx shape [4] idx [0 0 1 0]
```
The first output doesn’t make sense. The shape doesn’t even match the printed tensor.

Investigating further with a dataset:

```python
ds = tf.data.Dataset.from_tensor_slices(c).repeat(40).batch(4)
_ = graph_func(next(iter(ds)))
_ = eager_func(next(iter(ds)))
```
Prints this:
```
idx shape [4 3] idx [0 0 1 0]
idx shape [4] idx [0 0 1 0]
```
`graph_func` is executed in graph mode. The behavior is still unexpect (shape `[4 3]` instead of `[4]`).

But if we the data comes from the dataset through a `map` function for example (both functions are executed in graph mode), it works as expected:
```
_ = next(iter(ds.map(graph_func)))
_ = next(iter(ds.map(eager_func)))
```

This time, prints the expected result:
```
idx shape [4] idx [0 0 1 0]
idx shape [4] idx [0 0 1 0]
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
